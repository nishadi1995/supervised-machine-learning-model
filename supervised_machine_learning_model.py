# -*- coding: utf-8 -*-
"""supervised machine learning model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uGksJDtbmiA_NlCdrn8hHGoESm_S_5QQ

**A supervised machine learning model to identify liver patients**


> Dataset has 894 samples 

> Training Dataset consists of 583 samples

> Testing Dataset consists of 311 samples
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.metrics import classification_report,confusion_matrix

#load training and testing data seperatly
train_data = pd.read_csv('train.csv')
test_data = pd.read_csv('test.csv')

train_data.shape

### preprocessing ###

#replace ? with NaN in both train and test data sets
train_data = train_data.replace('?', np.NaN)
test_data = test_data.replace('?', np.NaN)

# drop all rows with any NaN values in both train and test data sets
train_data = train_data.dropna()
test_data = test_data.dropna()

train_data.shape

### making data set ready to do feature selection ###

#convert object type to int64
train_data['Gender']= train_data.Gender.map(dict(Female=1, Male=0))
train_data['Class']= train_data.Class.map(dict(Yes=1, No=0))

test_data['Gender']= test_data.Gender.map(dict(Female=1, Male=0))
test_data['Class']= test_data.Class.map(dict(Yes=1, No=0))

#convert object type to float64
for column in ['TB','DB','ALK','SGPT','SGOT','TP','ALB','AG_Ratio']:
  train_data[column] = train_data[column].astype(float)

for column in ['TB','DB','ALK','SGPT','SGOT','TP','ALB','AG_Ratio']:
  test_data[column] = test_data[column].astype(float)
  
train_data.info()

#since ID is not a feature, remove ID colomn
train_data = train_data.drop(columns="ID")
test_data = test_data.drop(columns="ID")

#verify ID column has removed
train_data.head()

### Feature Selection ###
#using filter method --> identify input features having high correlation with target variable

#print the correlation of each input feature with the class variable
importances = train_data.drop("Class", axis=1).apply(lambda x: x.corr(train_data.Class))
indices = np.argsort(importances)
importances[indices]

#cut-off = 0.16

names=['Age','Gender','TB','DB','ALK','SGPT','SGOT','TP','ALB','AG_Ration']

#printing selected Features
for i in range(0, len(indices)):
    if np.abs(importances[i])>0.16:
        print(names[i])

#training/testing data set with only selected features
train_data = train_data.drop(['Age','Gender','SGOT','TP'],axis=1)
test_data = test_data.drop(['Age','Gender','SGOT','TP'],axis=1)

#verifing training data has only selected features
train_data.head(2)

#class colomn 
y_train = train_data['Class'].copy()
y_test = test_data['Class'].copy()

#remove class colomn and create data frame
x_train = train_data.drop(columns="Class")
x_test = test_data.drop(columns="Class")

#verifing the data frame to train
x_train.head(2)

### creating input functions to supply data ###

# Create a input function to train the model
input_func_train = tf.compat.v1.estimator.inputs.pandas_input_fn(x=x_train,y=y_train, batch_size=50,shuffle=True)

# Create a input function to evaluate the model after train
input_func_test = tf.compat.v1.estimator.inputs.pandas_input_fn(x=x_test,y=y_test, batch_size=50,shuffle=False)

# Create a input function for prediction
input_func_prediction = tf.compat.v1.estimator.inputs.pandas_input_fn(x=x_test,y=y_test, batch_size=50,shuffle=False)

### creating a list of feature columns that describes each of the features to pass to the model ###

# Defining the model's feature columns
my_feature_columns = []

for col in x_train.columns:
  my_feature_columns.append(tf.feature_column.numeric_column(col))

# Print feature columns
my_feature_columns

### Build a DNN with 3 hidden layers and 100,100,10 neurons in each layer###

classifier = tf.estimator.DNNClassifier(
    
  feature_columns= my_feature_columns,
  hidden_units=[100,100,100],

  # The model must choose between 2 classes.
  n_classes=2
)

### Train the model ###
classifier.train(input_fn=input_func_train, steps=50)

### Evaluate the model ###
eval_result = classifier.evaluate(input_func_test, steps=len(x_test))
print('\nTest set accuracy: {accuracy:0.3f}\n'.format(**eval_result))

### making predictions from the trained model ###

predictions = list(classifier.predict(input_fn=input_func_prediction))

final_predictions = []
for pred in predictions:
    final_predictions.append(pred['class_ids'][0])

### Evaluations ###

print('Classification Reprt: \n')
print(classification_report(y_test,final_predictions))
print('\nConfusion Matrix: \n')
print(confusion_matrix(y_test,final_predictions))